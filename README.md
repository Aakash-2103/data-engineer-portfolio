# data-engineer-portfolio
ğŸ“Š Near Real-Time Stock Data Pipeline â€” API â†’ AWS S3 â†’ Snowflake

In todayâ€™s trading world, â³ speed = money.
This project demonstrates how to design and implement an end-to-end stock market data pipeline that fetches fresh stock prices via REST API, processes them in Python, stores them in AWS S3, and makes them analytics-ready in Snowflake.

ğŸ›  Tech Stack

Extraction: MarketStack REST API (Postman for testing, Python requests, pandas)

Transformation: Python (pandas) for cleaning, deduplication, timestamp formatting

Storage: AWS S3 (secure, scalable landing zone)

Analytics: Snowflake (fast queries, scalable compute, BI-ready)

âš™ Workflow

1ï¸âƒ£ API Data Extraction

Tested MarketStack API endpoints in Postman

Automated Python script (extract_market.py) pulls EOD data for multiple stock symbols

2ï¸âƒ£ Data Transformation

Script: transform.py

Removed duplicates, filled missing values, formatted dates, sorted for analytics

Saved clean dataset as transformed_stock_data_<timestamp>.csv

3ï¸âƒ£ Load to AWS S3

Script: s3.py

Created S3 bucket & programmatically uploaded data via Boto3

4ï¸âƒ£ Snowflake Integration

Created Storage Integration in Snowflake

Defined External Stage pointing to S3 bucket

Loaded staged CSV into MARKET_STACK table

ğŸ“‚ Repository Structure
â”œâ”€â”€ extract_market.py                # Fetch stock data from MarketStack API
â”œâ”€â”€ transform.py                     # Clean & transform raw data
â”œâ”€â”€ s3.py                            # Upload transformed data to AWS S3
â”œâ”€â”€ raw_stock_data_<timestamp>.csv   # Example raw dataset
â”œâ”€â”€ transformed_stock_data_<ts>.csv  # Example transformed dataset
â”œâ”€â”€ README.md                        # Project documentation
â””â”€â”€ .DS_Store                        # (ignore, MacOS artifact)

ğŸ’¡ Why This Architecture?

â˜ AWS S3 â†’ Cheap, scalable, secure raw data storage

âš¡ Snowflake â†’ High-speed analytics, BI integration, and joins with other datasets

ğŸ“ˆ Business Impact

âš¡ Faster Decisions: Traders access fresh data in minutes

ğŸ“Š Scalable: Handles millions of rows effortlessly

ğŸ’° Cost-Efficient: Pay only when querying/processing in Snowflake

ğŸ’¼ Monetization Ready: Curated datasets can be sold or integrated into premium platforms

ğŸš€ How to Run Locally

Clone this repo:

git clone https://github.com/<your-username>/<your-repo>.git
cd <your-repo>


Install dependencies:

pip install -r requirements.txt


Configure your API Key (from MarketStack) in extract_market.py

Run the pipeline step by step:

python extract_market.py
python transform.py
python s3.py


Verify Snowflake table load:

SELECT * FROM MARKET_STACK LIMIT 10;

ğŸ“Œ Future Improvements

 Automate pipeline with Airflow or AWS Lambda

 Implement near real-time streaming with Kafka/Kinesis

 Add CI/CD pipeline for deployment

âœ¨ Author

ğŸ‘¤ Aakash Sandela

LinkedIn: linkedin.com/in/aakashsandela

GitHub: github.com/Aakash-2103
